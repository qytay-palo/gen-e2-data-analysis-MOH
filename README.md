# MOH Polyclinic Data Analysis - Automated Extraction System

Automated data extraction, validation, and ETL pipeline for MOH polyclinic data analysis.

## Overview

This project provides a comprehensive automated system for extracting and processing polyclinic data from MOH databases. Built to support strategic policy planning, resource allocation, population health initiatives, and healthcare quality improvements.

### Key Features

- âœ… **Automated Data Extraction** - Incremental and full extraction modes with checkpoint management
- âœ… **Multi-Database Support** - PostgreSQL, MySQL, MS SQL Server, Oracle
- âœ… **Data Quality Validation** - Comprehensive validation checks for data integrity
- âœ… **ETL Pipeline** - Complete Extract-Transform-Load workflow orchestration
- âœ… **Scheduled Automation** - Daily, weekly, and monthly automated runs
- âœ… **Monitoring & Alerts** - Performance tracking and failure notifications
- âœ… **Logging & Audit** - Comprehensive logging for compliance and troubleshooting

## Quick Start

### Install Dependencies
```bash
pip install -r requirements.txt
```

### Configure Database
```bash
cp .env.example .env
# Edit .env with your database credentials
```

### Run First Extraction
```bash
# Extract patient data from last 7 days
python scripts/run_extraction.py --sources patients --last-n-days 7
```

ğŸ“– **[Full Quick Start Guide](docs/QUICK_START.md)** | ğŸ“š **[Complete Documentation](docs/DATA_EXTRACTION_GUIDE.md)**

## System Components

### 1. Configuration (`config/`)
- **database.yml** - Database connections, extraction settings, validation rules
- **queries.yml** - SQL query templates for data extraction

### 2. Data Processing (`src/data_processing/`)
- **db_connector.py** - Database connection management
- **data_extractor.py** - Data extraction with batching and retry logic
- **data_validator.py** - Data quality validation checks
- **etl_pipeline.py** - Complete ETL workflow orchestration

### 3. Utilities (`src/utils/`)
- **logging_config.py** - Logging configuration and structured logging
- **monitoring.py** - Performance monitoring and alerting

### 4. Scripts (`scripts/`)
- **run_extraction.py** - Manual data extraction with CLI options
- **run_scheduler.py** - Automated scheduler for recurring jobs

## Usage Examples

### Manual Extraction

```bash
# Extract specific sources
python scripts/run_extraction.py --sources attendances diagnoses

# Extract date range
python scripts/run_extraction.py \
  --sources all \
  --start-date 2025-01-01 \
  --end-date 2025-01-31

# Full extraction (not incremental)
python scripts/run_extraction.py --sources all --full
```

### Python API

```python
from src.data_processing.etl_pipeline import ETLPipeline

pipeline = ETLPipeline()
result = pipeline.run_full_pipeline(
    sources=['attendances', 'diagnoses'],
    start_date='2025-01-01',
    incremental=True
)
```

### Automated Scheduling

```bash
# Start scheduler for automated runs
python scripts/run_scheduler.py
```

## Project Structure

```
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ database.yml       # Database and extraction config
â”‚   â””â”€â”€ queries.yml        # SQL query templates
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ data_processing/   # ETL components
â”‚   â”œâ”€â”€ utils/            # Logging, monitoring
â”‚   â”œâ”€â”€ analysis/         # Analysis modules (future)
â”‚   â””â”€â”€ visualization/    # Visualization tools (future)
â”œâ”€â”€ scripts/              # Executable scripts
â”‚   â”œâ”€â”€ run_extraction.py
â”‚   â””â”€â”€ run_scheduler.py
â”œâ”€â”€ data/                 # Data storage
â”‚   â”œâ”€â”€ raw/             # Raw extracted data
â”‚   â”œâ”€â”€ processed/       # Cleaned data
â”‚   â””â”€â”€ interim/         # Intermediate files
â”œâ”€â”€ logs/                # Log files
â”œâ”€â”€ results/             # Analysis outputs
â”‚   â””â”€â”€ metrics/         # Execution metrics
â””â”€â”€ docs/                # Documentation
    â”œâ”€â”€ QUICK_START.md
    â”œâ”€â”€ DATA_EXTRACTION_GUIDE.md
    â”œâ”€â”€ objectives/      # Project objectives
    â””â”€â”€ data_dictionary/ # Data schemas
```

## Data Sources

The system supports extraction from:
- **Attendances** - Patient visits and appointments
- **Patients** - Demographics and registration data
- **Diagnoses** - Diagnosis records with ICD codes
- **Procedures** - Medical procedures and treatments
- **Medications** - Prescription records
- **Lab Results** - Laboratory test results
- **Reference Data** - Polyclinics, conditions, and master data

## Monitoring & Outputs

### Log Files
- `logs/extraction.log` - Main extraction activities
- `logs/errors.log` - Error tracking
- `logs/audit.log` - Structured audit trail

### Outputs
- `data/raw/` - Raw extracted data (Parquet/CSV)
- `data/processed/` - Cleaned, analysis-ready data
- `results/metrics/` - Execution summaries and performance metrics

## Project Objectives

This system supports MOH's strategic objectives:
- ğŸ“Š **Strategic Planning** - Long-term healthcare capacity and funding
- ğŸ¥ **Resource Allocation** - Equitable distribution across polyclinics
- ğŸ‘¥ **Population Health** - Demographic analysis and health equity
- ğŸ“ˆ **Quality of Care** - Clinical outcomes and best practices
- ğŸ”„ **System Integration** - Data sharing with NEHR and hospitals

See [User Stories](docs/objectives/01-user-stores.md) and [Agile Stories](docs/objectives/02-agile-user-stories.md) for detailed requirements.

## Requirements

- Python 3.8+
- PostgreSQL/MySQL/MS SQL Server/Oracle
- 2GB+ RAM (for large extractions)
- Required packages: pandas, pyarrow, pyyaml, psycopg2, schedule, psutil

## Documentation

- ğŸ“– [Quick Start Guide](docs/QUICK_START.md) - Get started in 5 minutes
- ğŸ“š [Complete Documentation](docs/DATA_EXTRACTION_GUIDE.md) - Full system guide
- ğŸ¯ [Project Objectives](docs/objectives/) - User stories and requirements
- ğŸ“‹ [Data Dictionary](docs/data_dictionary/) - Data schemas and definitions

## License

Internal MOH use only. Confidential and proprietary.

---

**Version**: 1.0  
**Last Updated**: 2026-01-26  
**Maintained By**: MOH Data Analytics Team
